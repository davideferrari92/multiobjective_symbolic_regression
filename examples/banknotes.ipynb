{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "# to include the SR code without installing in the environment\n",
    "from symbolic_regression.SymbolicRegressor import SymbolicRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The operations\n",
    "\n",
    "Here we define the list of allowed operations. In this project we implemented most of the arithmetic operations we expect to need in a normal use. Please have a look at the file in `symbolic_regression/operators.py` to see how we define them and to define your own operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbolic_regression.operators import *\n",
    "\n",
    "operations = [\n",
    "    OPERATOR_ADD,\n",
    "    OPERATOR_SUB,\n",
    "    OPERATOR_MUL,\n",
    "    OPERATOR_DIV,\n",
    "    # OPERATOR_ABS,\n",
    "    # OPERATOR_MOD,\n",
    "    # OPERATOR_NEG,\n",
    "    # OPERATOR_INV,\n",
    "    OPERATOR_LOG,\n",
    "    OPERATOR_EXP,\n",
    "    OPERATOR_POW,\n",
    "    OPERATOR_SQRT,\n",
    "    OPERATOR_MAX,\n",
    "    OPERATOR_MIN\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The example dataset: counterfeit banknotes classification\n",
    "\n",
    "This is a very simple binary classification task to predict whether a banknote is counterfeit based on four characteristics. This dataset is publicly available on [Kaggle](https://www.kaggle.com/datasets/ritesaluja/bank-note-authentication-uci-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./banknotes.csv')\n",
    "\n",
    "data = data.sample(frac=1)  # To shuffle the dataset.\n",
    "\n",
    "data['w'] = np.where(data['y'] == 1, 1./(2*data['y'].mean()),\n",
    "                     1./(2*(1-data['y'].mean())))\n",
    "\n",
    "features = ['x1', 'x2', 'x3', 'x4']\n",
    "target = 'y'\n",
    "weights = 'w'\n",
    "\n",
    "print(f'Dataset {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, stratify=data[target])\n",
    "\n",
    "print(f'Train {train.shape}')\n",
    "print(f'Test {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the base range for which to generate the constants in the individuals. Furthermore, we also define how to optimize those constants in order to make them converge to the best value they can have in their expression.\n",
    "\n",
    "We are using ADAM with the following configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_range = (0, 1)\n",
    "\n",
    "constants_optimization = 'scipy'\n",
    "constants_optimization_conf = {'task': 'binary:logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbolic_regression.multiobjective.fitness.Classification import Accuracy, BCEAkaike, BinaryCrossentropy, AUC, ClassificationMinimumDescriptionLength, F1Score, Precision, Recall, Specificity\n",
    "from symbolic_regression.multiobjective.fitness.Regression import NotConstant\n",
    "\n",
    "fitness_functions = [\n",
    "    BinaryCrossentropy(label='BCE', target=target, weights=weights,\n",
    "                       logistic=True, minimize=True,\n",
    "                       constants_optimization=constants_optimization, constants_optimization_conf=constants_optimization_conf),\n",
    "\n",
    "\n",
    "    # Add also the other metrics with minimize=False so that they are not used\n",
    "    # for optimization but only for visualization. You can use minimize=True\n",
    "    # for those metrics that you want push the model to prioritize one or more\n",
    "    # metrics over the others, but remember to change the one_minus to True as\n",
    "    # this algorithm work on minimization problems. Just add the same metric another\n",
    "    # time with minimize=True and one_minus=True to have both the version of the metric\n",
    "    # in the optimization and the one for visualization.\n",
    "\n",
    "    Accuracy(label='Accuracy', target=target, weights=weights, threshold=.5,\n",
    "             logistic=True, one_minus=False, minimize=False),\n",
    "    Precision(label='Precision', target=target, weights=weights, threshold=.5,\n",
    "              logistic=True, one_minus=False, minimize=False),\n",
    "    Recall(label='Sensitivity (Recall)', target=target, weights=weights, threshold=.5,\n",
    "           logistic=True, one_minus=False, minimize=False),\n",
    "    Specificity(label='Specificity', target=target, weights=weights, threshold=.5,\n",
    "                logistic=True, one_minus=False, minimize=False),\n",
    "    F1Score(label='F1', target=target, weights=weights, threshold=.5,\n",
    "            logistic=True, one_minus=False, minimize=False),\n",
    "    AUC(label='AUC', target=target, weights=weights, convergence_threshold=0.1,\n",
    "        logistic=True, one_minus=False, minimize=False),\n",
    "\n",
    "    # For demonstration purposes only. We need the 1-F1 score to be minimized.\n",
    "    # Use this in imbalanced datasets.\n",
    "    F1Score(label='1-F1', target=target, weights=weights, threshold=.5,\n",
    "            logistic=True, one_minus=True, minimize=True),\n",
    "]\n",
    "\n",
    "''' Use this to modulate the relative frequency of genetic operations\n",
    "    E.g., crossover is chosen 2 times more frequently than mutation\n",
    "        {\n",
    "            'crossover': 2,\n",
    "            'mutation': 1,\n",
    "            # etc...\n",
    "        }\n",
    "'''\n",
    "genetic_operators_frequency = {\n",
    "    'crossover': 1,\n",
    "    'randomize': 1,\n",
    "    'mutation': 1,\n",
    "    'insert_node': 1,\n",
    "    'delete_node': 1,\n",
    "    'mutate_leaf': 1,\n",
    "    'mutate_operator': 1,\n",
    "    'recalibrate': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbolic_regression.callbacks.CallbackSave import MOSRCallbackSaveCheckpoint\n",
    "from symbolic_regression.callbacks.CallbackStatistics import MOSRHistory, MOSRStatisticsComputation\n",
    "\n",
    "file_name = f'./banknotes'\n",
    "\n",
    "callbacks = [\n",
    "    MOSRCallbackSaveCheckpoint(\n",
    "        checkpoint_file=file_name, checkpoint_frequency=1, checkpoint_overwrite=True),\n",
    "    MOSRStatisticsComputation(),\n",
    "    MOSRHistory(history_fpf_frequency=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 100\n",
    "TOURNAMENT_SIZE = 3\n",
    "\n",
    "logging.info(f'Running with POPULATION_SIZE {POPULATION_SIZE}')\n",
    "logging.info(f'Running with TOURNAMENT_SIZE {TOURNAMENT_SIZE}')\n",
    "\n",
    "\n",
    "sr = SymbolicRegressor(\n",
    "    client_name='client',\n",
    "    const_range=const_range,\n",
    "    parsimony=.80,\n",
    "    parsimony_decay=.85,  # Expected depth = parsimony / (1-parsimony_decay)\n",
    "    population_size=POPULATION_SIZE,\n",
    "    tournament_size=TOURNAMENT_SIZE,\n",
    "    genetic_operators_frequency=genetic_operators_frequency,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENERATIONS = 100\n",
    "\n",
    "sr.fit(\n",
    "    data=train,\n",
    "    val_data=test,\n",
    "    features=features,\n",
    "    operations=operations,\n",
    "    fitness_functions=fitness_functions,\n",
    "    generations_to_train=GENERATIONS,\n",
    "    n_jobs=-1,\n",
    "    stop_at_convergence=True,\n",
    "    convergence_rolling_window=5,\n",
    "    verbose=1  # The output could be very verbose. Consider using 0, 1, or 2 to reduce the verbosity\n",
    ")\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access the models and use them\n",
    "\n",
    "You can access the models from ```sr.population: List``` or from ```sr.first_pareto_front: List```. The first one contains all the models generated during the evolution process, while the second one contains only the models that are in the Pareto front.\n",
    "\n",
    "E.g., \n",
    "```python\n",
    "model = sr.population[0]  # OR model = sr.first_pareto_front[0]\n",
    "```\n",
    "\n",
    "To see the model expression, use\n",
    "```python\n",
    ">>> str(model.program)  # It is only the string representation\n",
    "```\n",
    "\n",
    "Some relevant attributes of the model are\n",
    "```python\n",
    ">>> model.features_used\n",
    ">>> model.fitness\n",
    ">>> model.fitness_validation\n",
    "```\n",
    "\n",
    "To evaluate the model, use\n",
    "```python\n",
    ">>> model.evaluate(data)  # data should be a Dict, pd.Series or pd.DataFrame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sr.population[0]\n",
    "\n",
    "str(model.program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nModel complexity:\\n\\t{model.complexity}\")\n",
    "print(f\"\\nModel fitness:\\n\\t{model.fitness}\")\n",
    "# Is empty if no validation set is provided\n",
    "# print(f\"\\nModel fitness_validation:\\n\\t{model.fitness_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(data=data[features], logistic=True).round(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
